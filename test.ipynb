{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datamodule import CT_Datamodule\n",
    "from torchvision.transforms import functional as TF\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = CT_Datamodule(\"Dataset\", num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.prepare_data()\n",
    "d.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stats(loader: torch.utils.data.DataLoader):\n",
    "    \"\"\"\n",
    "    Calculate the mean and standard deviation of the data in the loader\n",
    "\n",
    "    Args:\n",
    "        loader (torch.utils.data.DataLoader): The data loader\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor]: The channel-wise mean and standard deviation of the data\n",
    "    \"\"\"\n",
    "    psum = torch.tensor([0.0] * loader.dataset[0][2][0].shape[0])\n",
    "    psum_sq = torch.tensor([0.0] * loader.dataset[0][2][0].shape[0])\n",
    "\n",
    "    for _, _, inputs, _ in loader:\n",
    "        inputs = inputs[0]\n",
    "        psum += inputs.sum(axis=[0, 2, 3])\n",
    "        psum_sq += (inputs**2).sum(axis=[0, 2, 3])\n",
    "\n",
    "    count = (\n",
    "        len(loader.dataset)\n",
    "        * loader.dataset[0][2][0].shape[1]\n",
    "        * loader.dataset[0][2][0].shape[2]\n",
    "    )\n",
    "\n",
    "    total_mean = psum / count\n",
    "    total_var = (psum_sq / count) - (total_mean**2)\n",
    "    total_std = torch.sqrt(total_var)\n",
    "    return total_mean, total_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1737, 0.1737, 0.1737]), tensor([0.2584, 0.2584, 0.2584]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_stats(d.train_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "samples_reg = torch.zeros(4)\n",
    "samples_tum = torch.zeros(4)\n",
    "\n",
    "for i, j, _, _ in d.train:\n",
    "    samples_reg += i\n",
    "    samples_tum += j\n",
    "\n",
    "for i, j, _, _ in d.val:\n",
    "    samples_reg += i\n",
    "    samples_tum += j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 99., 362., 114.,  75.], dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_tum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Owais Makroo/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
      "C:\\Users\\Owais Makroo/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "C:\\Users\\Owais Makroo/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "C:\\Users\\Owais Makroo/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/dinov2/dinov2_vitb14/dinov2_vitb14_pretrain.pth\" to C:\\Users\\Owais Makroo/.cache\\torch\\hub\\checkpoints\\dinov2_vitb14_pretrain.pth\n",
      "100%|██████████| 330M/330M [00:10<00:00, 32.0MB/s] \n"
     ]
    }
   ],
   "source": [
    "m= torch.hub.load(\"facebookresearch/dinov2\", \"dinov2_vitb14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DinoVisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x NestedTensorBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MemEffAttention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (head): Identity()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DinoVisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 384, kernel_size=(14, 14), stride=(14, 14))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x NestedTensorBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MemEffAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "  (head): Identity()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Owais Makroo/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
      "C:\\Users\\Owais Makroo/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "C:\\Users\\Owais Makroo/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "C:\\Users\\Owais Makroo/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n"
     ]
    }
   ],
   "source": [
    "m = Classifier(1e-3, 2e-5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import SupervisedContrastiveLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = SupervisedContrastiveLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2, 16])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(32, 16)\n",
    "x = torch.concat([x.unsqueeze(1), x.unsqueeze(1)], dim=1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1657)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {key: [] for key in data[\"0\"].keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data:\n",
    "    for k in data[i]:\n",
    "        res[k].append(data[i][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss 19.424339543788115 11.35818379459751\n",
      "val_f1 0.5310939371585846 0.0570391465157692\n",
      "val_auc 0.722384387254715 0.06477022132861987\n",
      "val_acc 0.564117756485939 0.08067464243507903\n",
      "val_rec 0.564117756485939 0.08067464243507903\n",
      "val_acc_0 0.49425640925765035 0.22620277776124015\n",
      "val_acc_1 0.7205801129341125 0.11028153409786116\n",
      "val_acc_2 0.5709743678569794 0.10636846443750053\n",
      "val_acc_3 0.3978461615741253 0.2689560374464342\n",
      "val_f1_0 0.37585037648677827 0.12278642596907881\n",
      "val_f1_1 0.7277752935886384 0.07073368233283246\n",
      "val_f1_2 0.5706884235143661 0.0905883162652921\n",
      "val_f1_3 0.3773333504796028 0.2124755841919272\n",
      "val_auc_0 0.7277935326099396 0.10562361868561365\n",
      "val_auc_1 0.7736896991729736 0.04758807745181345\n",
      "val_auc_2 0.7712440669536591 0.07989227453259277\n",
      "val_auc_3 0.6168102502822876 0.2224773177507702\n",
      "val_rec_0 0.49425640925765035 0.22620277776124015\n",
      "val_rec_1 0.7205801129341125 0.11028153409786116\n",
      "val_rec_2 0.5709743678569794 0.10636846443750053\n",
      "val_rec_3 0.3978461615741253 0.2689560374464342\n"
     ]
    }
   ],
   "source": [
    "for k in res:\n",
    "    res[k] = np.array(res[k])\n",
    "    print(k, res[k].mean(), res[k].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
